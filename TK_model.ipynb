{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d319faf-92b1-47cd-8054-70bbec119cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "0.9074074074074074\n",
      "[[91  2]\n",
      " [ 8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        93\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.91       108\n",
      "   macro avg       0.85      0.72      0.77       108\n",
      "weighted avg       0.90      0.91      0.90       108\n",
      "\n",
      "(357, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am7574\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n",
      "0.9166666666666666\n",
      "[[93  0]\n",
      " [ 9  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        93\n",
      "           1       1.00      0.40      0.57        15\n",
      "\n",
      "    accuracy                           0.92       108\n",
      "   macro avg       0.96      0.70      0.76       108\n",
      "weighted avg       0.92      0.92      0.90       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "45 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.86359184 0.87567347 0.86759184 0.86359184 0.8515102  0.86759184\n",
      " 0.8675102  0.87159184 0.86759184 0.83934694 0.8595102  0.83526531\n",
      " 0.8595102  0.82734694 0.8595102  0.81934694 0.8595102  0.82734694\n",
      " 0.8595102  0.81534694 0.8595102  0.83534694 0.8595102  0.81934694\n",
      " 0.8595102  0.82334694 0.8595102  0.81534694 0.8595102  0.8635102\n",
      " 0.8635102  0.8635102  0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.8635102  0.86359184 0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.86359184 0.85142857 0.8635102  0.86359184 0.8675102  0.8635102\n",
      " 0.86759184 0.8555102  0.86359184 0.85942857 0.83918367 0.86359184\n",
      " 0.87159184 0.85142857 0.8555102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.8425925925925926\n",
      "[[91  2]\n",
      " [15  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91        93\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.84       108\n",
      "   macro avg       0.43      0.49      0.46       108\n",
      "weighted avg       0.74      0.84      0.79       108\n",
      "\n",
      "(357, 30)\n",
      "0.2857142857142857\n",
      "0.8611111111111112\n",
      "[[90  3]\n",
      " [12  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92        93\n",
      "           1       0.50      0.20      0.29        15\n",
      "\n",
      "    accuracy                           0.86       108\n",
      "   macro avg       0.69      0.58      0.60       108\n",
      "weighted avg       0.83      0.86      0.83       108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' X_new = getBestFeatureSFS(X, y)\\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \\ngetBestModel(X_train, y_train, X_test, y_test) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rdkit\n",
    "\n",
    "stFile = r\"C:\\Users\\am7574\\OneDrive - Corteva\\Documents\\Projects\\AI_chemistry\\TK_AI\\TK_ALL.sdf\"\n",
    "data = PandasTools.LoadSDF(stFile)\n",
    "dataMol = data[[\"ROMol\",\"IC50 uM\"]]\n",
    "dataMol = dataMol.dropna()\n",
    "dataMol['activity'] = dataMol['IC50 uM'].apply(lambda x: 0 if x == 'NI' or float(x) >= 20 else 1)\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def calcFingerprint(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    dataMol[\"MolFP\"] = sdData[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcProp(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in rdkit.Chem.Descriptors._descList])\n",
    "    dataMol[\"prop\"] = sdData[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcFingerprint(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    mols[\"MolFP\"] = mols[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return mols\n",
    "\n",
    "def calcProp(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "    des_name = [x[0] for x in rdkit.Chem.Descriptors._descList if (x[0].find(\"PartialCharge\") == -1 and x[0].find(\"BCUT2D\")==-1 and x[0].find(\"Morgan\") == -1)]\n",
    "    #print(des_name)  \n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator(des_name)\n",
    "    mols[\"prop\"] = mols[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return mols\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def getBestModel(X_train, y_train, X_test, y_test):\n",
    "    from sklearn import pipeline\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    import numpy as np    \n",
    "    pipe = pipeline.Pipeline([('classifier', RandomForestClassifier())])\n",
    "    search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__max_features': [1, 2, 3]},\n",
    "                    {'classifier': [LogisticRegression(solver='liblinear')],\n",
    "                     'classifier__penalty': ['l1', 'l2'],\n",
    "                     'classifier__C': np.logspace(0, 4, 10)},\n",
    "                    {'classifier': [GradientBoostingClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__learning_rate': [0.001, 0.01, 0.1],\n",
    "                     'classifier__max_depth': [1, 2, 3]},\n",
    "                     {'classifier': [AdaBoostClassifier()]},\n",
    "                        {'classifier': [SVC()],\n",
    "                        'classifier__C': [0.1, 1, 10],\n",
    "                        'classifier__gamma': [1, 0.1, 0.01],\n",
    "                        'classifier__kernel': ['rbf', 'poly', 'sigmoid']},\n",
    "                    ]\n",
    "    \n",
    "    clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    assessModel(y_test, y_pred)\n",
    "    return best_model\n",
    "\n",
    "def getBestfeatures(X,y):\n",
    "    from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "    X_new = SelectKBest(mutual_info_classif, k=30).fit_transform(X, y)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "def getBestFeatureSFS(X,y):\n",
    "    from sklearn.feature_selection import SequentialFeatureSelector\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    sfs_fwd = SequentialFeatureSelector(RandomForestClassifier(), n_features_to_select=30, direction='backward').fit(X, y)\n",
    "    X_new = sfs_fwd.transform(X)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "X_fp = calcFingerprint(dataMol)\n",
    "X = X_fp[\"MolFP\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\"\n",
    "\n",
    "X_prop = calcProp(dataMol)\n",
    "X = X_prop[\"prop\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426eb3c-cf5e-47aa-b0ba-21993ee2fafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "0.9074074074074074\n",
      "[[91  2]\n",
      " [ 8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        93\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.91       108\n",
      "   macro avg       0.85      0.72      0.77       108\n",
      "weighted avg       0.90      0.91      0.90       108\n",
      "\n",
      "(357, 35)\n",
      "0.6923076923076923\n",
      "0.9259259259259259\n",
      "[[91  2]\n",
      " [ 6  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        93\n",
      "           1       0.82      0.60      0.69        15\n",
      "\n",
      "    accuracy                           0.93       108\n",
      "   macro avg       0.88      0.79      0.83       108\n",
      "weighted avg       0.92      0.93      0.92       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "45 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\am7574\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.86367347 0.87559184 0.87159184 0.87159184 0.86759184 0.86759184\n",
      " 0.86359184 0.87159184 0.86759184 0.83126531 0.8595102  0.83526531\n",
      " 0.8595102  0.82326531 0.8595102  0.83134694 0.8595102  0.81534694\n",
      " 0.8595102  0.81126531 0.8595102  0.81934694 0.8595102  0.81934694\n",
      " 0.8595102  0.81134694 0.8595102  0.81134694 0.8595102  0.8635102\n",
      " 0.8635102  0.8635102  0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.8635102  0.86359184 0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.86359184 0.85142857 0.8635102  0.86359184 0.8675102  0.8635102\n",
      " 0.86759184 0.8555102  0.86359184 0.85942857 0.83918367 0.86759184\n",
      " 0.85534694 0.84326531 0.8555102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38095238095238093\n",
      "0.8796296296296297\n",
      "[[91  2]\n",
      " [11  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        93\n",
      "           1       0.67      0.27      0.38        15\n",
      "\n",
      "    accuracy                           0.88       108\n",
      "   macro avg       0.78      0.62      0.66       108\n",
      "weighted avg       0.86      0.88      0.86       108\n",
      "\n",
      "(357, 35)\n",
      "0.45454545454545453\n",
      "0.8888888888888888\n",
      "[[91  2]\n",
      " [10  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        93\n",
      "           1       0.71      0.33      0.45        15\n",
      "\n",
      "    accuracy                           0.89       108\n",
      "   macro avg       0.81      0.66      0.70       108\n",
      "weighted avg       0.88      0.89      0.87       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am7574\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' X_new = getBestFeatureSFS(X, y)\\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \\ngetBestModel(X_train, y_train, X_test, y_test) '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rdkit\n",
    "\n",
    "stFile = r\"C:\\Users\\am7574\\OneDrive - Corteva\\Documents\\Projects\\AI_chemistry\\TK_AI\\TK_ALL.sdf\"\n",
    "data = PandasTools.LoadSDF(stFile)\n",
    "dataMol = data[[\"ROMol\",\"IC50 uM\"]]\n",
    "dataMol = dataMol.dropna()\n",
    "dataMol['activity'] = dataMol['IC50 uM'].apply(lambda x: 0 if x == 'NI' or float(x) >= 20 else 1)\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def calcFingerprint(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    dataMol[\"MolFP\"] = sdData[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcProp(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in rdkit.Chem.Descriptors._descList])\n",
    "    dataMol[\"prop\"] = sdData[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcFingerprint(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    mols[\"MolFP\"] = mols[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return mols\n",
    "\n",
    "def calcProp(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "    des_name = [x[0] for x in rdkit.Chem.Descriptors._descList if (x[0].find(\"PartialCharge\") == -1 and x[0].find(\"BCUT2D\")==-1 and x[0].find(\"Morgan\") == -1)]\n",
    "    #print(des_name)  \n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator(des_name)\n",
    "    mols[\"prop\"] = mols[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return mols\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def getBestModel(X_train, y_train, X_test, y_test):\n",
    "    from sklearn import pipeline\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    import numpy as np    \n",
    "    pipe = pipeline.Pipeline([('classifier', RandomForestClassifier())])\n",
    "    search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__max_features': [1, 2, 3]},\n",
    "                    {'classifier': [LogisticRegression(solver='liblinear')],\n",
    "                     'classifier__penalty': ['l1', 'l2'],\n",
    "                     'classifier__C': np.logspace(0, 4, 10)},\n",
    "                    {'classifier': [GradientBoostingClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__learning_rate': [0.001, 0.01, 0.1],\n",
    "                     'classifier__max_depth': [1, 2, 3]},\n",
    "                     {'classifier': [AdaBoostClassifier()]},\n",
    "                        {'classifier': [SVC()],\n",
    "                        'classifier__C': [0.1, 1, 10],\n",
    "                        'classifier__gamma': [1, 0.1, 0.01],\n",
    "                        'classifier__kernel': ['rbf', 'poly', 'sigmoid']},\n",
    "                    ]\n",
    "    \n",
    "    clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    assessModel(y_test, y_pred)\n",
    "    return best_model\n",
    "\n",
    "def getBestfeatures(X,y):\n",
    "    from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "    X_new = SelectKBest(mutual_info_classif, k=35).fit_transform(X, y)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "def getBestFeatureSFS(X,y):\n",
    "    from sklearn.feature_selection import SequentialFeatureSelector\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    sfs_fwd = SequentialFeatureSelector(RandomForestClassifier(), n_features_to_select=30, direction='backward').fit(X, y)\n",
    "    X_new = sfs_fwd.transform(X)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "X_fp = calcFingerprint(dataMol)\n",
    "X = X_fp[\"MolFP\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\"\n",
    "\n",
    "X_prop = calcProp(dataMol)\n",
    "X = X_prop[\"prop\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4999f9eb-447a-496b-9ac1-0a7d294f5bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "0.9074074074074074\n",
      "[[91  2]\n",
      " [ 8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        93\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.91       108\n",
      "   macro avg       0.85      0.72      0.77       108\n",
      "weighted avg       0.90      0.91      0.90       108\n",
      "\n",
      "(357, 40)\n",
      "0.72\n",
      "0.9351851851851852\n",
      "[[92  1]\n",
      " [ 6  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        93\n",
      "           1       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.92      0.79      0.84       108\n",
      "weighted avg       0.93      0.94      0.93       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "45 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.87567347 0.86359184 0.86759184 0.85142857 0.86759184 0.86759184\n",
      " 0.8675102  0.86359184 0.86759184 0.83534694 0.8595102  0.83526531\n",
      " 0.8595102  0.83134694 0.8595102  0.81134694 0.8595102  0.81934694\n",
      " 0.8595102  0.81934694 0.8595102  0.81534694 0.8595102  0.83934694\n",
      " 0.8595102  0.83134694 0.8595102  0.81534694 0.8595102  0.8635102\n",
      " 0.8635102  0.8635102  0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.8635102  0.86359184 0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.86359184 0.8555102  0.8635102  0.86359184 0.8675102  0.8635102\n",
      " 0.86759184 0.8555102  0.86359184 0.85942857 0.83926531 0.86359184\n",
      " 0.8715102  0.83918367 0.8555102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3157894736842105\n",
      "0.8796296296296297\n",
      "[[92  1]\n",
      " [12  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        93\n",
      "           1       0.75      0.20      0.32        15\n",
      "\n",
      "    accuracy                           0.88       108\n",
      "   macro avg       0.82      0.59      0.62       108\n",
      "weighted avg       0.87      0.88      0.85       108\n",
      "\n",
      "(357, 40)\n",
      "0.21052631578947367\n",
      "0.8611111111111112\n",
      "[[91  2]\n",
      " [13  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92        93\n",
      "           1       0.50      0.13      0.21        15\n",
      "\n",
      "    accuracy                           0.86       108\n",
      "   macro avg       0.69      0.56      0.57       108\n",
      "weighted avg       0.82      0.86      0.82       108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' X_new = getBestFeatureSFS(X, y)\\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \\ngetBestModel(X_train, y_train, X_test, y_test) '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rdkit\n",
    "\n",
    "stFile = r\"C:\\Users\\am7574\\OneDrive - Corteva\\Documents\\Projects\\AI_chemistry\\TK_AI\\TK_ALL.sdf\"\n",
    "data = PandasTools.LoadSDF(stFile)\n",
    "dataMol = data[[\"ROMol\",\"IC50 uM\"]]\n",
    "dataMol = dataMol.dropna()\n",
    "dataMol['activity'] = dataMol['IC50 uM'].apply(lambda x: 0 if x == 'NI' or float(x) >= 20 else 1)\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def calcFingerprint(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    dataMol[\"MolFP\"] = sdData[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcProp(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in rdkit.Chem.Descriptors._descList])\n",
    "    dataMol[\"prop\"] = sdData[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcFingerprint(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    mols[\"MolFP\"] = mols[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return mols\n",
    "\n",
    "def calcProp(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "    des_name = [x[0] for x in rdkit.Chem.Descriptors._descList if (x[0].find(\"PartialCharge\") == -1 and x[0].find(\"BCUT2D\")==-1 and x[0].find(\"Morgan\") == -1)]\n",
    "    #print(des_name)  \n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator(des_name)\n",
    "    mols[\"prop\"] = mols[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return mols\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def getBestModel(X_train, y_train, X_test, y_test):\n",
    "    from sklearn import pipeline\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    import numpy as np    \n",
    "    pipe = pipeline.Pipeline([('classifier', RandomForestClassifier())])\n",
    "    search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__max_features': [1, 2, 3]},\n",
    "                    {'classifier': [LogisticRegression(solver='liblinear')],\n",
    "                     'classifier__penalty': ['l1', 'l2'],\n",
    "                     'classifier__C': np.logspace(0, 4, 10)},\n",
    "                    {'classifier': [GradientBoostingClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__learning_rate': [0.001, 0.01, 0.1],\n",
    "                     'classifier__max_depth': [1, 2, 3]},\n",
    "                     {'classifier': [AdaBoostClassifier()]},\n",
    "                        {'classifier': [SVC()],\n",
    "                        'classifier__C': [0.1, 1, 10],\n",
    "                        'classifier__gamma': [1, 0.1, 0.01],\n",
    "                        'classifier__kernel': ['rbf', 'poly', 'sigmoid']},\n",
    "                    ]\n",
    "    \n",
    "    clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    assessModel(y_test, y_pred)\n",
    "    return best_model\n",
    "\n",
    "def getBestfeatures(X,y):\n",
    "    from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "    X_new = SelectKBest(mutual_info_classif, k=40).fit_transform(X, y)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "def getBestFeatureSFS(X,y):\n",
    "    from sklearn.feature_selection import SequentialFeatureSelector\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    sfs_fwd = SequentialFeatureSelector(RandomForestClassifier(), n_features_to_select=30, direction='backward').fit(X, y)\n",
    "    X_new = sfs_fwd.transform(X)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "X_fp = calcFingerprint(dataMol)\n",
    "X = X_fp[\"MolFP\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\"\n",
    "\n",
    "X_prop = calcProp(dataMol)\n",
    "X = X_prop[\"prop\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431001ec-0a1b-4dcc-ab08-542345a8bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "0.9074074074074074\n",
      "[[91  2]\n",
      " [ 8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        93\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.91       108\n",
      "   macro avg       0.85      0.72      0.77       108\n",
      "weighted avg       0.90      0.91      0.90       108\n",
      "\n",
      "(357, 45)\n",
      "0.72\n",
      "0.9351851851851852\n",
      "[[92  1]\n",
      " [ 6  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        93\n",
      "           1       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.92      0.79      0.84       108\n",
      "weighted avg       0.93      0.94      0.93       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "45 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.86759184 0.86759184 0.86359184 0.8675102  0.86359184 0.86759184\n",
      " 0.85942857 0.85959184 0.86759184 0.83934694 0.8595102  0.82318367\n",
      " 0.8595102  0.82734694 0.8595102  0.82734694 0.8595102  0.81534694\n",
      " 0.8595102  0.83534694 0.8595102  0.81934694 0.8595102  0.82334694\n",
      " 0.8595102  0.82334694 0.8595102  0.81518367 0.8595102  0.8635102\n",
      " 0.8635102  0.8635102  0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.8635102  0.86359184 0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.86359184 0.85142857 0.8635102  0.86359184 0.8675102  0.8635102\n",
      " 0.86759184 0.8595102  0.86359184 0.85934694 0.83518367 0.86367347\n",
      " 0.85942857 0.85542857 0.8555102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21052631578947367\n",
      "0.8611111111111112\n",
      "[[91  2]\n",
      " [13  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92        93\n",
      "           1       0.50      0.13      0.21        15\n",
      "\n",
      "    accuracy                           0.86       108\n",
      "   macro avg       0.69      0.56      0.57       108\n",
      "weighted avg       0.82      0.86      0.82       108\n",
      "\n",
      "(357, 45)\n",
      "0.2857142857142857\n",
      "0.8611111111111112\n",
      "[[90  3]\n",
      " [12  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92        93\n",
      "           1       0.50      0.20      0.29        15\n",
      "\n",
      "    accuracy                           0.86       108\n",
      "   macro avg       0.69      0.58      0.60       108\n",
      "weighted avg       0.83      0.86      0.83       108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' X_new = getBestFeatureSFS(X, y)\\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \\ngetBestModel(X_train, y_train, X_test, y_test) '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rdkit\n",
    "\n",
    "stFile = r\"C:\\Users\\am7574\\OneDrive - Corteva\\Documents\\Projects\\AI_chemistry\\TK_AI\\TK_ALL.sdf\"\n",
    "data = PandasTools.LoadSDF(stFile)\n",
    "dataMol = data[[\"ROMol\",\"IC50 uM\"]]\n",
    "dataMol = dataMol.dropna()\n",
    "dataMol['activity'] = dataMol['IC50 uM'].apply(lambda x: 0 if x == 'NI' or float(x) >= 20 else 1)\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def calcFingerprint(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    dataMol[\"MolFP\"] = sdData[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcProp(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in rdkit.Chem.Descriptors._descList])\n",
    "    dataMol[\"prop\"] = sdData[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcFingerprint(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    mols[\"MolFP\"] = mols[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return mols\n",
    "\n",
    "def calcProp(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "    des_name = [x[0] for x in rdkit.Chem.Descriptors._descList if (x[0].find(\"PartialCharge\") == -1 and x[0].find(\"BCUT2D\")==-1 and x[0].find(\"Morgan\") == -1)]\n",
    "    #print(des_name)  \n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator(des_name)\n",
    "    mols[\"prop\"] = mols[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return mols\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def getBestModel(X_train, y_train, X_test, y_test):\n",
    "    from sklearn import pipeline\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    import numpy as np    \n",
    "    pipe = pipeline.Pipeline([('classifier', RandomForestClassifier())])\n",
    "    search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__max_features': [1, 2, 3]},\n",
    "                    {'classifier': [LogisticRegression(solver='liblinear')],\n",
    "                     'classifier__penalty': ['l1', 'l2'],\n",
    "                     'classifier__C': np.logspace(0, 4, 10)},\n",
    "                    {'classifier': [GradientBoostingClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__learning_rate': [0.001, 0.01, 0.1],\n",
    "                     'classifier__max_depth': [1, 2, 3]},\n",
    "                     {'classifier': [AdaBoostClassifier()]},\n",
    "                        {'classifier': [SVC()],\n",
    "                        'classifier__C': [0.1, 1, 10],\n",
    "                        'classifier__gamma': [1, 0.1, 0.01],\n",
    "                        'classifier__kernel': ['rbf', 'poly', 'sigmoid']},\n",
    "                    ]\n",
    "    \n",
    "    clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    assessModel(y_test, y_pred)\n",
    "    return best_model\n",
    "\n",
    "def getBestfeatures(X,y):\n",
    "    from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "    X_new = SelectKBest(mutual_info_classif, k=45).fit_transform(X, y)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "def getBestFeatureSFS(X,y):\n",
    "    from sklearn.feature_selection import SequentialFeatureSelector\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    sfs_fwd = SequentialFeatureSelector(RandomForestClassifier(), n_features_to_select=30, direction='backward').fit(X, y)\n",
    "    X_new = sfs_fwd.transform(X)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "X_fp = calcFingerprint(dataMol)\n",
    "X = X_fp[\"MolFP\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\"\n",
    "\n",
    "X_prop = calcProp(dataMol)\n",
    "X = X_prop[\"prop\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d308824-dc7f-4756-bf56-e5d0a931bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am7574\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "0.9074074074074074\n",
      "[[91  2]\n",
      " [ 8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        93\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.91       108\n",
      "   macro avg       0.85      0.72      0.77       108\n",
      "weighted avg       0.90      0.91      0.90       108\n",
      "\n",
      "(357, 50)\n",
      "0.7333333333333333\n",
      "0.9259259259259259\n",
      "[[89  4]\n",
      " [ 4 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        93\n",
      "           1       0.73      0.73      0.73        15\n",
      "\n",
      "    accuracy                           0.93       108\n",
      "   macro avg       0.85      0.85      0.85       108\n",
      "weighted avg       0.93      0.93      0.93       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "45 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\am7574\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\miniforge3\\envs\\chem\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.86742857 0.85959184 0.86759184 0.8555102  0.86359184 0.86759184\n",
      " 0.87159184 0.86759184 0.86759184 0.83134694 0.8595102  0.83126531\n",
      " 0.8595102  0.82734694 0.8595102  0.83534694 0.8595102  0.82334694\n",
      " 0.8595102  0.81526531 0.8595102  0.81926531 0.8595102  0.82334694\n",
      " 0.8595102  0.82334694 0.8595102  0.83134694 0.8595102  0.8635102\n",
      " 0.8635102  0.8635102  0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.8635102  0.86359184 0.8635102  0.8635102  0.86359184 0.8635102\n",
      " 0.86359184 0.85142857 0.8635102  0.86359184 0.8675102  0.8635102\n",
      " 0.86759184 0.8515102  0.86359184 0.85942857 0.83118367 0.8595102\n",
      " 0.85942857 0.85542857 0.8555102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102\n",
      " 0.8635102         nan 0.8635102  0.8635102         nan 0.8635102 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21052631578947367\n",
      "0.8611111111111112\n",
      "[[91  2]\n",
      " [13  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92        93\n",
      "           1       0.50      0.13      0.21        15\n",
      "\n",
      "    accuracy                           0.86       108\n",
      "   macro avg       0.69      0.56      0.57       108\n",
      "weighted avg       0.82      0.86      0.82       108\n",
      "\n",
      "(357, 50)\n",
      "0.21052631578947367\n",
      "0.8611111111111112\n",
      "[[91  2]\n",
      " [13  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92        93\n",
      "           1       0.50      0.13      0.21        15\n",
      "\n",
      "    accuracy                           0.86       108\n",
      "   macro avg       0.69      0.56      0.57       108\n",
      "weighted avg       0.82      0.86      0.82       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am7574\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' X_new = getBestFeatureSFS(X, y)\\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \\ngetBestModel(X_train, y_train, X_test, y_test) '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rdkit\n",
    "\n",
    "stFile = r\"C:\\Users\\am7574\\OneDrive - Corteva\\Documents\\Projects\\AI_chemistry\\TK_AI\\TK_ALL.sdf\"\n",
    "data = PandasTools.LoadSDF(stFile)\n",
    "dataMol = data[[\"ROMol\",\"IC50 uM\"]]\n",
    "dataMol = dataMol.dropna()\n",
    "dataMol['activity'] = dataMol['IC50 uM'].apply(lambda x: 0 if x == 'NI' or float(x) >= 20 else 1)\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def calcFingerprint(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    dataMol[\"MolFP\"] = sdData[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcProp(stFile: str) -> pd.DataFrame:\n",
    "    from rdkit.Chem import PandasTools\n",
    "    sdData = PandasTools.LoadSDF(stFile)\n",
    "    dataMol = sdData[[\"ROMol\"]]\n",
    "    dataMol = sdData.dropna()\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in rdkit.Chem.Descriptors._descList])\n",
    "    dataMol[\"prop\"] = sdData[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return dataMol\n",
    "\n",
    "def calcFingerprint(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    mfpGen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    mols[\"MolFP\"] = mols[\"ROMol\"].apply(lambda x:mfpGen.GetCountFingerprintAsNumPy(x))\n",
    "    return mols\n",
    "\n",
    "def calcProp(mols: pd.DataFrame) -> pd.DataFrame:\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "    des_name = [x[0] for x in rdkit.Chem.Descriptors._descList if (x[0].find(\"PartialCharge\") == -1 and x[0].find(\"BCUT2D\")==-1 and x[0].find(\"Morgan\") == -1)]\n",
    "    #print(des_name)  \n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator(des_name)\n",
    "    mols[\"prop\"] = mols[\"ROMol\"].apply(lambda x:calc.CalcDescriptors(x))\n",
    "    return mols\n",
    "\n",
    "def assessModel(y_test, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def getBestModel(X_train, y_train, X_test, y_test):\n",
    "    from sklearn import pipeline\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    import numpy as np    \n",
    "    pipe = pipeline.Pipeline([('classifier', RandomForestClassifier())])\n",
    "    search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__max_features': [1, 2, 3]},\n",
    "                    {'classifier': [LogisticRegression(solver='liblinear')],\n",
    "                     'classifier__penalty': ['l1', 'l2'],\n",
    "                     'classifier__C': np.logspace(0, 4, 10)},\n",
    "                    {'classifier': [GradientBoostingClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__learning_rate': [0.001, 0.01, 0.1],\n",
    "                     'classifier__max_depth': [1, 2, 3]},\n",
    "                     {'classifier': [AdaBoostClassifier()]},\n",
    "                        {'classifier': [SVC()],\n",
    "                        'classifier__C': [0.1, 1, 10],\n",
    "                        'classifier__gamma': [1, 0.1, 0.01],\n",
    "                        'classifier__kernel': ['rbf', 'poly', 'sigmoid']},\n",
    "                    ]\n",
    "    \n",
    "    clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    assessModel(y_test, y_pred)\n",
    "    return best_model\n",
    "\n",
    "def getBestfeatures(X,y):\n",
    "    from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "    X_new = SelectKBest(mutual_info_classif, k=50).fit_transform(X, y)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "def getBestFeatureSFS(X,y):\n",
    "    from sklearn.feature_selection import SequentialFeatureSelector\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    sfs_fwd = SequentialFeatureSelector(RandomForestClassifier(), n_features_to_select=30, direction='backward').fit(X, y)\n",
    "    X_new = sfs_fwd.transform(X)\n",
    "    print(X_new.shape)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "X_fp = calcFingerprint(dataMol)\n",
    "X = X_fp[\"MolFP\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\"\n",
    "\n",
    "X_prop = calcProp(dataMol)\n",
    "X = X_prop[\"prop\"].to_list()\n",
    "y = dataMol['activity'].to_list()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "X_new = getBestfeatures(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "getBestModel(X_train, y_train, X_test, y_test)\n",
    "\"\"\" X_new = getBestFeatureSFS(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)   \n",
    "getBestModel(X_train, y_train, X_test, y_test) \"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
